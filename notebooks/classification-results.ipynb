{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from rvae.utils.paths import RESULTS_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_30238/1200770556.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  classification_results = torch.load(\n"
     ]
    }
   ],
   "source": [
    "classification_results = torch.load(\n",
    "    RESULTS_PATH / \"predictions.pt\", map_location=torch.device(\"cpu\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "import torch\n",
    "\n",
    "\n",
    "def compute_f1_each_model(predictions, targets):\n",
    "    \"\"\"\n",
    "    Computes the F1 score for each Fashion MNIST class separately for each model,\n",
    "    then computes the mean and standard deviation across models for each class.\n",
    "\n",
    "    Args:\n",
    "        predictions: A list of predictions from different models. Each element\n",
    "            in the list should be a 1D NumPy array or a PyTorch tensor\n",
    "            containing the predicted labels for a single model.\n",
    "        targets: A 1D NumPy array or PyTorch tensor containing the true labels.\n",
    "\n",
    "    Returns:\n",
    "        f1_scores: A NumPy array of shape (num_models, num_classes) containing the\n",
    "            F1 score for each class for each model.\n",
    "        mean_f1: A NumPy array containing the mean F1 score across models for each class.\n",
    "        std_f1: A NumPy array containing the standard deviation of the F1 scores across models for each class.\n",
    "    \"\"\"\n",
    "    # Convert predictions and targets to NumPy arrays if necessary.\n",
    "    preds_np = [\n",
    "        p.detach().cpu().numpy() if isinstance(p, torch.Tensor) else p\n",
    "        for p in predictions\n",
    "    ]\n",
    "    targets_np = (\n",
    "        targets.detach().cpu().numpy() if isinstance(targets, torch.Tensor) else targets\n",
    "    )\n",
    "\n",
    "    f1_scores = []\n",
    "    for p in preds_np:\n",
    "        # Compute the per-class F1 score for this model.\n",
    "        score = f1_score(targets_np, p, average=None)\n",
    "        f1_scores.append(score)\n",
    "\n",
    "    # Stack F1 scores into a (num_models, num_classes) array.\n",
    "    f1_scores = np.vstack(f1_scores)\n",
    "\n",
    "    # Compute the mean and standard deviation across models for each class.\n",
    "    mean_f1 = f1_scores.mean(axis=0)\n",
    "    std_f1 = f1_scores.std(axis=0)\n",
    "\n",
    "    return f1_scores, mean_f1, std_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = {}\n",
    "\n",
    "for model_type in classification_results.keys():\n",
    "    f1[model_type] = {}\n",
    "    for latent_dim in classification_results[model_type].keys():\n",
    "        targets = classification_results[model_type][latent_dim][\"targets\"]\n",
    "        preds = classification_results[model_type][latent_dim][\"predictions\"]\n",
    "        f1[model_type][latent_dim] = {}\n",
    "        # f1s_ = []\n",
    "        # for pred in preds:\n",
    "        # print(f\"DEBUG: {pred.shape=} | {targets.shape=}\")\n",
    "        # f1s_.append(\n",
    "        #     compute_f1_per_class(\n",
    "        #         predictions=pred.unsqueeze(1), targets=targets.unsqueeze(1)\n",
    "        #     )\n",
    "        # )\n",
    "        _, f1[model_type][latent_dim][\"mean\"], f1[model_type][latent_dim][\"std\"] = (\n",
    "            compute_f1_each_model(predictions=preds, targets=targets)\n",
    "        )\n",
    "        # = torch.stack(f1s_, dim=0).mean(dim=0)\n",
    "        # compute_f1_per_class(\n",
    "        # f1[model_type][latent_dim] =\n",
    "        #     embeddings=embeddings,\n",
    "        #     method_type=\"RVAE\",\n",
    "        #     latent_dim=latent_dim,\n",
    "        #     subsample=None,\n",
    "        # )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'VAE': {2: {'mean': array([0.7101347 , 0.92609256, 0.55994447, 0.67642076, 0.38041697,\n",
       "          0.83592986, 0.16341775, 0.82145799, 0.94002201, 0.89061103]),\n",
       "   'std': array([0.01010988, 0.00384236, 0.00934278, 0.01490139, 0.02176035,\n",
       "          0.00506805, 0.04334456, 0.00292756, 0.00154986, 0.00438412])},\n",
       "  5: {'mean': array([0.77110685, 0.96872954, 0.65665407, 0.823877  , 0.67234746,\n",
       "          0.89441048, 0.43884465, 0.87829376, 0.94163189, 0.90188134]),\n",
       "   'std': array([0.00458958, 0.00230181, 0.01010306, 0.00820092, 0.00947848,\n",
       "          0.0036794 , 0.02339079, 0.00459297, 0.0035077 , 0.00230825])},\n",
       "  10: {'mean': array([0.77488302, 0.96360167, 0.70119244, 0.82807512, 0.7447622 ,\n",
       "          0.91804083, 0.52244228, 0.90231195, 0.95020883, 0.92045273]),\n",
       "   'std': array([0.00322552, 0.00184557, 0.01553325, 0.00278505, 0.00593542,\n",
       "          0.00379485, 0.01610617, 0.00135521, 0.00227852, 0.00214556])}},\n",
       " 'RVAE': {2: {'mean': array([0.71239713, 0.92614889, 0.5613906 , 0.67660056, 0.36624325,\n",
       "          0.82812412, 0.20999888, 0.82106472, 0.94026223, 0.88938761]),\n",
       "   'std': array([0.01394247, 0.00204102, 0.00266204, 0.01739079, 0.00727997,\n",
       "          0.00792915, 0.04219502, 0.00454794, 0.00097794, 0.00324747])},\n",
       "  5: {'mean': array([0.76966109, 0.96625407, 0.65516917, 0.8193377 , 0.67013514,\n",
       "          0.89484753, 0.42172712, 0.87630453, 0.94115282, 0.9025747 ]),\n",
       "   'std': array([0.00361155, 0.0013293 , 0.00798018, 0.00548417, 0.01797777,\n",
       "          0.00398659, 0.02260656, 0.00469695, 0.00544677, 0.00224815])},\n",
       "  10: {'mean': array([0.775877  , 0.96410468, 0.70048744, 0.82818468, 0.73879058,\n",
       "          0.92054238, 0.52285347, 0.9036273 , 0.9526158 , 0.92294965]),\n",
       "   'std': array([0.00068957, 0.00182155, 0.00986461, 0.00330462, 0.01038759,\n",
       "          0.0021936 , 0.01122565, 0.00299955, 0.00199705, 0.00160328])}}}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_f1 = {\n",
    "    (outer, inner, inner2): arr1\n",
    "    for outer, inner_dict in f1.items()\n",
    "    for inner, arr in inner_dict.items()\n",
    "    for inner2, arr1 in arr.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('VAE',\n",
       "  2,\n",
       "  'mean'): array([0.7101347 , 0.92609256, 0.55994447, 0.67642076, 0.38041697,\n",
       "        0.83592986, 0.16341775, 0.82145799, 0.94002201, 0.89061103]),\n",
       " ('VAE',\n",
       "  2,\n",
       "  'std'): array([0.01010988, 0.00384236, 0.00934278, 0.01490139, 0.02176035,\n",
       "        0.00506805, 0.04334456, 0.00292756, 0.00154986, 0.00438412]),\n",
       " ('VAE',\n",
       "  5,\n",
       "  'mean'): array([0.77110685, 0.96872954, 0.65665407, 0.823877  , 0.67234746,\n",
       "        0.89441048, 0.43884465, 0.87829376, 0.94163189, 0.90188134]),\n",
       " ('VAE',\n",
       "  5,\n",
       "  'std'): array([0.00458958, 0.00230181, 0.01010306, 0.00820092, 0.00947848,\n",
       "        0.0036794 , 0.02339079, 0.00459297, 0.0035077 , 0.00230825]),\n",
       " ('VAE',\n",
       "  10,\n",
       "  'mean'): array([0.77488302, 0.96360167, 0.70119244, 0.82807512, 0.7447622 ,\n",
       "        0.91804083, 0.52244228, 0.90231195, 0.95020883, 0.92045273]),\n",
       " ('VAE',\n",
       "  10,\n",
       "  'std'): array([0.00322552, 0.00184557, 0.01553325, 0.00278505, 0.00593542,\n",
       "        0.00379485, 0.01610617, 0.00135521, 0.00227852, 0.00214556]),\n",
       " ('RVAE',\n",
       "  2,\n",
       "  'mean'): array([0.71239713, 0.92614889, 0.5613906 , 0.67660056, 0.36624325,\n",
       "        0.82812412, 0.20999888, 0.82106472, 0.94026223, 0.88938761]),\n",
       " ('RVAE',\n",
       "  2,\n",
       "  'std'): array([0.01394247, 0.00204102, 0.00266204, 0.01739079, 0.00727997,\n",
       "        0.00792915, 0.04219502, 0.00454794, 0.00097794, 0.00324747]),\n",
       " ('RVAE',\n",
       "  5,\n",
       "  'mean'): array([0.76966109, 0.96625407, 0.65516917, 0.8193377 , 0.67013514,\n",
       "        0.89484753, 0.42172712, 0.87630453, 0.94115282, 0.9025747 ]),\n",
       " ('RVAE',\n",
       "  5,\n",
       "  'std'): array([0.00361155, 0.0013293 , 0.00798018, 0.00548417, 0.01797777,\n",
       "        0.00398659, 0.02260656, 0.00469695, 0.00544677, 0.00224815]),\n",
       " ('RVAE',\n",
       "  10,\n",
       "  'mean'): array([0.775877  , 0.96410468, 0.70048744, 0.82818468, 0.73879058,\n",
       "        0.92054238, 0.52285347, 0.9036273 , 0.9526158 , 0.92294965]),\n",
       " ('RVAE',\n",
       "  10,\n",
       "  'std'): array([0.00068957, 0.00182155, 0.00986461, 0.00330462, 0.01038759,\n",
       "        0.0021936 , 0.01122565, 0.00299955, 0.00199705, 0.00160328])}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(data=flat_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">VAE</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th>mean</th>\n",
       "      <td>0.710135</td>\n",
       "      <td>0.926093</td>\n",
       "      <td>0.559944</td>\n",
       "      <td>0.676421</td>\n",
       "      <td>0.380417</td>\n",
       "      <td>0.835930</td>\n",
       "      <td>0.163418</td>\n",
       "      <td>0.821458</td>\n",
       "      <td>0.940022</td>\n",
       "      <td>0.890611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.010110</td>\n",
       "      <td>0.003842</td>\n",
       "      <td>0.009343</td>\n",
       "      <td>0.014901</td>\n",
       "      <td>0.021760</td>\n",
       "      <td>0.005068</td>\n",
       "      <td>0.043345</td>\n",
       "      <td>0.002928</td>\n",
       "      <td>0.001550</td>\n",
       "      <td>0.004384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">5</th>\n",
       "      <th>mean</th>\n",
       "      <td>0.771107</td>\n",
       "      <td>0.968730</td>\n",
       "      <td>0.656654</td>\n",
       "      <td>0.823877</td>\n",
       "      <td>0.672347</td>\n",
       "      <td>0.894410</td>\n",
       "      <td>0.438845</td>\n",
       "      <td>0.878294</td>\n",
       "      <td>0.941632</td>\n",
       "      <td>0.901881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.004590</td>\n",
       "      <td>0.002302</td>\n",
       "      <td>0.010103</td>\n",
       "      <td>0.008201</td>\n",
       "      <td>0.009478</td>\n",
       "      <td>0.003679</td>\n",
       "      <td>0.023391</td>\n",
       "      <td>0.004593</td>\n",
       "      <td>0.003508</td>\n",
       "      <td>0.002308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">10</th>\n",
       "      <th>mean</th>\n",
       "      <td>0.774883</td>\n",
       "      <td>0.963602</td>\n",
       "      <td>0.701192</td>\n",
       "      <td>0.828075</td>\n",
       "      <td>0.744762</td>\n",
       "      <td>0.918041</td>\n",
       "      <td>0.522442</td>\n",
       "      <td>0.902312</td>\n",
       "      <td>0.950209</td>\n",
       "      <td>0.920453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.003226</td>\n",
       "      <td>0.001846</td>\n",
       "      <td>0.015533</td>\n",
       "      <td>0.002785</td>\n",
       "      <td>0.005935</td>\n",
       "      <td>0.003795</td>\n",
       "      <td>0.016106</td>\n",
       "      <td>0.001355</td>\n",
       "      <td>0.002279</td>\n",
       "      <td>0.002146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">RVAE</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th>mean</th>\n",
       "      <td>0.712397</td>\n",
       "      <td>0.926149</td>\n",
       "      <td>0.561391</td>\n",
       "      <td>0.676601</td>\n",
       "      <td>0.366243</td>\n",
       "      <td>0.828124</td>\n",
       "      <td>0.209999</td>\n",
       "      <td>0.821065</td>\n",
       "      <td>0.940262</td>\n",
       "      <td>0.889388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.013942</td>\n",
       "      <td>0.002041</td>\n",
       "      <td>0.002662</td>\n",
       "      <td>0.017391</td>\n",
       "      <td>0.007280</td>\n",
       "      <td>0.007929</td>\n",
       "      <td>0.042195</td>\n",
       "      <td>0.004548</td>\n",
       "      <td>0.000978</td>\n",
       "      <td>0.003247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">5</th>\n",
       "      <th>mean</th>\n",
       "      <td>0.769661</td>\n",
       "      <td>0.966254</td>\n",
       "      <td>0.655169</td>\n",
       "      <td>0.819338</td>\n",
       "      <td>0.670135</td>\n",
       "      <td>0.894848</td>\n",
       "      <td>0.421727</td>\n",
       "      <td>0.876305</td>\n",
       "      <td>0.941153</td>\n",
       "      <td>0.902575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.003612</td>\n",
       "      <td>0.001329</td>\n",
       "      <td>0.007980</td>\n",
       "      <td>0.005484</td>\n",
       "      <td>0.017978</td>\n",
       "      <td>0.003987</td>\n",
       "      <td>0.022607</td>\n",
       "      <td>0.004697</td>\n",
       "      <td>0.005447</td>\n",
       "      <td>0.002248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">10</th>\n",
       "      <th>mean</th>\n",
       "      <td>0.775877</td>\n",
       "      <td>0.964105</td>\n",
       "      <td>0.700487</td>\n",
       "      <td>0.828185</td>\n",
       "      <td>0.738791</td>\n",
       "      <td>0.920542</td>\n",
       "      <td>0.522853</td>\n",
       "      <td>0.903627</td>\n",
       "      <td>0.952616</td>\n",
       "      <td>0.922950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.000690</td>\n",
       "      <td>0.001822</td>\n",
       "      <td>0.009865</td>\n",
       "      <td>0.003305</td>\n",
       "      <td>0.010388</td>\n",
       "      <td>0.002194</td>\n",
       "      <td>0.011226</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.001997</td>\n",
       "      <td>0.001603</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0         1         2         3         4         5  \\\n",
       "VAE  2  mean  0.710135  0.926093  0.559944  0.676421  0.380417  0.835930   \n",
       "        std   0.010110  0.003842  0.009343  0.014901  0.021760  0.005068   \n",
       "     5  mean  0.771107  0.968730  0.656654  0.823877  0.672347  0.894410   \n",
       "        std   0.004590  0.002302  0.010103  0.008201  0.009478  0.003679   \n",
       "     10 mean  0.774883  0.963602  0.701192  0.828075  0.744762  0.918041   \n",
       "        std   0.003226  0.001846  0.015533  0.002785  0.005935  0.003795   \n",
       "RVAE 2  mean  0.712397  0.926149  0.561391  0.676601  0.366243  0.828124   \n",
       "        std   0.013942  0.002041  0.002662  0.017391  0.007280  0.007929   \n",
       "     5  mean  0.769661  0.966254  0.655169  0.819338  0.670135  0.894848   \n",
       "        std   0.003612  0.001329  0.007980  0.005484  0.017978  0.003987   \n",
       "     10 mean  0.775877  0.964105  0.700487  0.828185  0.738791  0.920542   \n",
       "        std   0.000690  0.001822  0.009865  0.003305  0.010388  0.002194   \n",
       "\n",
       "                     6         7         8         9  \n",
       "VAE  2  mean  0.163418  0.821458  0.940022  0.890611  \n",
       "        std   0.043345  0.002928  0.001550  0.004384  \n",
       "     5  mean  0.438845  0.878294  0.941632  0.901881  \n",
       "        std   0.023391  0.004593  0.003508  0.002308  \n",
       "     10 mean  0.522442  0.902312  0.950209  0.920453  \n",
       "        std   0.016106  0.001355  0.002279  0.002146  \n",
       "RVAE 2  mean  0.209999  0.821065  0.940262  0.889388  \n",
       "        std   0.042195  0.004548  0.000978  0.003247  \n",
       "     5  mean  0.421727  0.876305  0.941153  0.902575  \n",
       "        std   0.022607  0.004697  0.005447  0.002248  \n",
       "     10 mean  0.522853  0.903627  0.952616  0.922950  \n",
       "        std   0.011226  0.003000  0.001997  0.001603  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lllrrrrrrrrrr}\n",
      "\\toprule\n",
      " &  &  & 0 & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 \\\\\n",
      "\\midrule\n",
      "\\multirow[t]{6}{*}{VAE} & \\multirow[t]{2}{*}{2} & mean & 0.710135 & 0.926093 & 0.559944 & 0.676421 & 0.380417 & 0.835930 & 0.163418 & 0.821458 & 0.940022 & 0.890611 \\\\\n",
      " &  & std & 0.010110 & 0.003842 & 0.009343 & 0.014901 & 0.021760 & 0.005068 & 0.043345 & 0.002928 & 0.001550 & 0.004384 \\\\\n",
      "\\cline{2-13}\n",
      " & \\multirow[t]{2}{*}{5} & mean & 0.771107 & 0.968730 & 0.656654 & 0.823877 & 0.672347 & 0.894410 & 0.438845 & 0.878294 & 0.941632 & 0.901881 \\\\\n",
      " &  & std & 0.004590 & 0.002302 & 0.010103 & 0.008201 & 0.009478 & 0.003679 & 0.023391 & 0.004593 & 0.003508 & 0.002308 \\\\\n",
      "\\cline{2-13}\n",
      " & \\multirow[t]{2}{*}{10} & mean & 0.774883 & 0.963602 & 0.701192 & 0.828075 & 0.744762 & 0.918041 & 0.522442 & 0.902312 & 0.950209 & 0.920453 \\\\\n",
      " &  & std & 0.003226 & 0.001846 & 0.015533 & 0.002785 & 0.005935 & 0.003795 & 0.016106 & 0.001355 & 0.002279 & 0.002146 \\\\\n",
      "\\cline{1-13} \\cline{2-13}\n",
      "\\multirow[t]{6}{*}{RVAE} & \\multirow[t]{2}{*}{2} & mean & 0.712397 & 0.926149 & 0.561391 & 0.676601 & 0.366243 & 0.828124 & 0.209999 & 0.821065 & 0.940262 & 0.889388 \\\\\n",
      " &  & std & 0.013942 & 0.002041 & 0.002662 & 0.017391 & 0.007280 & 0.007929 & 0.042195 & 0.004548 & 0.000978 & 0.003247 \\\\\n",
      "\\cline{2-13}\n",
      " & \\multirow[t]{2}{*}{5} & mean & 0.769661 & 0.966254 & 0.655169 & 0.819338 & 0.670135 & 0.894848 & 0.421727 & 0.876305 & 0.941153 & 0.902575 \\\\\n",
      " &  & std & 0.003612 & 0.001329 & 0.007980 & 0.005484 & 0.017978 & 0.003987 & 0.022607 & 0.004697 & 0.005447 & 0.002248 \\\\\n",
      "\\cline{2-13}\n",
      " & \\multirow[t]{2}{*}{10} & mean & 0.775877 & 0.964105 & 0.700487 & 0.828185 & 0.738791 & 0.920542 & 0.522853 & 0.903627 & 0.952616 & 0.922950 \\\\\n",
      " &  & std & 0.000690 & 0.001822 & 0.009865 & 0.003305 & 0.010388 & 0.002194 & 0.011226 & 0.003000 & 0.001997 & 0.001603 \\\\\n",
      "\\cline{1-13} \\cline{2-13}\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df.T.to_latex())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
